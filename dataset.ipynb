{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizer import Tokenizer\n",
    "from util import head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tokenizer.Tokenizer at 0x1060fa390>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.fit(['hello world', 'foo bar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = tok.texts_to_sequences(['hello world blub', 'foo bar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<bos> hello world <unk> <eos>', '<bos> foo bar <eos>']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.sequences_to_texts(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from util import load_or_compute\n",
    "from tokenizer import Tokenizer\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "SCTStories = namedtuple('SCTStories', ('begin', 'end_real', 'end_fake'))\n",
    "SCTSequences = namedtuple('SCTSequences', ('begin', 'end_real', 'end_fake'))\n",
    "\n",
    "def read_sct_stories(fname, skip_header=True):\n",
    "    beginnings = list()\n",
    "    real_endings = list()\n",
    "    fake_endings = list()\n",
    "    with open(fname) as f:\n",
    "        csvreader = csv.reader(f, delimiter=',')\n",
    "        if skip_header:\n",
    "            next(csvreader, None) # skip header\n",
    "        for row in csvreader:\n",
    "            if len(row) == 7: #ROCstories, only real endings\n",
    "                beginnings.extend(row[2:-1])\n",
    "                real_endings.append(row[-1])\n",
    "            elif len(row) == 8: #Eval/test set, real and fake endings\n",
    "                beginnings.extend(row[1:-3])\n",
    "                realid = int(row[-1])\n",
    "                if realid == 1:\n",
    "                    real_endings.append(row[-3])\n",
    "                    fake_endings.append(row[-2])\n",
    "                else:\n",
    "                    real_endings.append(row[-2])\n",
    "                    fake_endings.append(row[-3])\n",
    "            else:\n",
    "                raise Exception('wrong number of items in input file')\n",
    "    return SCTStories(beginnings, real_endings, fake_endings if len(fake_endings) > 0 else None)\n",
    "\n",
    "def sct_stories_to_sequences(texts_to_sequences_func, sct_stories, max_seq_len=90):\n",
    "    seq_b = pad_sequences(texts_to_sequences_func(sct_stories.begin), maxlen=max_seq_len)\n",
    "    seq_b = seq_b.reshape(seq_b.shape[0]//4, 4, seq_b.shape[1])\n",
    "    seq_r = pad_sequences(texts_to_sequences_func(sct_stories.end_real), maxlen=max_seq_len)\n",
    "    seq_f = None\n",
    "    if sct_stories.end_fake:\n",
    "        seq_f = pad_sequences(texts_to_sequences_func(sct_stories.end_fake), maxlen=max_seq_len)\n",
    "    return SCTSequences(seq_b, seq_r, seq_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train = read_sct_stories('data/sct_train.csv')\n",
    "texts_eval = read_sct_stories('data/sct_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer().fit(texts_train.begin + texts_train.end_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64647"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    352644.000000\n",
      "mean         44.065451\n",
      "std          13.230812\n",
      "min           9.000000\n",
      "25%          34.000000\n",
      "50%          44.000000\n",
      "75%          54.000000\n",
      "max          86.000000\n",
      "dtype: float64\n",
      "count    7484.000000\n",
      "mean       45.646045\n",
      "std        12.919189\n",
      "min        11.000000\n",
      "25%        36.000000\n",
      "50%        46.000000\n",
      "75%        56.000000\n",
      "max        72.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.Series([len(seq) for seq in texts_train.begin]).describe())\n",
    "print(pd.Series([len(seq) for seq in texts_eval.begin]).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = 'cache'\n",
    "os.makedirs(cache_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = load_or_compute(os.path.join(cache_dir, 'tokenizer.pickle'), tok.fit, texts_train.begin + texts_train.end_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_train = load_or_compute(os.path.join(cache_dir, 'train.pickle'), sct_stories_to_sequences, tok.texts_to_sequences, texts_train)\n",
    "seqs_eval = load_or_compute(os.path.join(cache_dir, 'eval.pickle'), sct_stories_to_sequences, tok.texts_to_sequences, texts_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
